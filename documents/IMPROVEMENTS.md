# Integration Testing & Improvements: Calendar Tool & Plan Generation

## Executive Summary
This document outlines the improvements made to the conversation service and plan generation pipeline to handle the JSON parsing error and implement a more robust placeholder-based approach for vague requests.

## Issues Identified & Fixed

### 1. **JSON Parsing Error in Tool Call Arguments**
**Problem:** 
- Error: `400 Failed to parse tool call arguments as JSON`
- Occurred when the LLM attempted to generate tool calls but produced malformed JSON
- This was caused by the LLM trying to call `planParallelActions` tool with improper argument formatting

**Root Cause:**
- The conversational stream was attempting to parse incomplete or malformed JSON from the LLM's tool call deltas
- No graceful fallback mechanism existed when tool calls failed to parse

**Solution Implemented:**
- Added resilient error handling in `runConversationalStream` to catch JSON parsing errors
- When a malformed tool call error is detected, the stream continues gracefully instead of crashing
- The system now falls back to plan generation with placeholders

### 2. **Over-Engineered Missing Parameter Handling**
**Problem:**
- The previous solution for handling missing parameters relied entirely on the LLM's `planParallelActions` tool
- This required the LLM to perfectly understand complex planning scenarios
- When tool call formatting failed, the entire pipeline broke

**Solution Implemented:**
- Introduced `generatePlanWithPlaceholders()` method in ConversationService
- Uses a dedicated prompt to instruct the LLM to generate plans with placeholder parameters
- Format: `{{PLACEHOLDER_parameter_name}}` for missing values
- Example: `{{PLACEHOLDER_meeting_title}}`, `{{PLACEHOLDER_attendee_email}}`, `{{PLACEHOLDER_start_time}}`

## Architecture Changes

### 3. **Parallel Conversational Response & Plan Generation**
**Implementation:**
```
User Request
    â†“
Conversational Stream (parallel)
â”œâ”€ Generate conversational response
â”œâ”€ Attempt tool call identification
â”œâ”€ If tool calls fail or missing parameters detected:
â”‚  â””â”€ Trigger plan generation with placeholders
â””â”€ Return both response + plan (if generated)

UI receives:
- Conversational message (always)
- Generated plan with placeholders (if applicable)
- Run state with action steps
```

**Benefits:**
- User always gets a conversational response, even if tool calls fail
- Plan generation happens automatically when needed
- Both responses stream simultaneously to the client
- UI can prompt for missing parameters without blocking conversation flow

### 4. **Improved Planner Prompt - Placeholder-Centric Design**

**Key Changes to `dedicatedPlannerPrompt.ts`:**

#### Old Approach:
```
- Mark status as "conditional" if parameters missing
- Require exact parameter values in arguments
- LLM must ask clarifying questions
- Plan execution blocked until parameters provided
```

#### New Approach:
```
- Use placeholders for missing parameters: {{PLACEHOLDER_name}}
- Always mark status as "ready"
- Plan proceeds to UI for parameter fulfillment
- Much simpler for LLM to understand and execute
- UI shows forms/prompts for placeholder fields
```

**Prompt Instructions:**
```
4. **HANDLING VAGUE REQUESTS - USE PLACEHOLDERS:**
   - If parameters are missing or vague, use placeholder format: {{PLACEHOLDER_parameter_name}}
   - DO NOT mark status as "conditional" when you can use placeholders
   - The UI will prompt the user to fill in placeholders
   - Example: {{PLACEHOLDER_meeting_title}}, {{PLACEHOLDER_attendee_email}}, {{PLACEHOLDER_start_time}}
   - Always set status to "ready" when using placeholders - the plan should proceed to execution
```

**Example Output:**
```json
{
  "plan": [
    {
      "id": "action_1",
      "intent": "Create a calendar meeting for the sales team",
      "tool": "create_calendar_event",
      "arguments": { 
        "title": "{{PLACEHOLDER_meeting_title}}",
        "startTime": "{{PLACEHOLDER_start_time}}",
        "duration": "{{PLACEHOLDER_duration_minutes}}",
        "attendees": ["{{PLACEHOLDER_attendee_email}}"]
      },
      "status": "ready",
      "requiredParams": []
    }
  ]
}
```

## Test Case: Calendar Meeting Creation

### User Input
```
"please make an exmple meetign nmycalednar"
(vague, has typos)
```

### Expected Flow with New Implementation

1. **Conversational Stream:**
   - LLM generates: "I'd love to help create a meeting. Let me set that up for you."
   - Attempts to identify tool: `create_calendar_event`
   - Tool call arguments malformed â†’ Caught gracefully

2. **Fallback to Plan Generation:**
   - `generatePlanWithPlaceholders()` called
   - Prompt instructs LLM: "Generate a plan even if parameters are vague, use placeholders"
   - LLM generates:
     ```json
     {
       "plan": [{
         "id": "action_1",
         "tool": "create_calendar_event",
         "intent": "Create a calendar meeting",
         "arguments": {
           "title": "{{PLACEHOLDER_meeting_title}}",
           "startTime": "{{PLACEHOLDER_start_time}}",
           "attendees": ["{{PLACEHOLDER_attendee_email}}"]
         },
         "status": "ready"
       }]
     }
     ```

3. **Response to Client:**
   - âœ… Conversational message: "I'll create a meeting for you"
   - âœ… Run object with action steps
   - âœ… UI displays form fields for: meeting_title, start_time, attendee_email
   - âœ… User fills in parameters
   - âœ… Execution proceeds with complete information

## Code Changes Summary

### Files Modified

#### 1. `src/services/conversation/ConversationService.ts`
**Changes:**
- Enhanced error handling in stream iteration (lines 375-421)
  - Catches malformed JSON errors gracefully
  - Continues processing instead of crashing
- Added `generatePlanWithPlaceholders()` method (lines 612-704)
  - Generates plans with placeholder parameters
  - Handles missing parameters elegantly
  - Returns ready-to-execute action steps
- Added fallback logic after conversational stream (lines 524-546)
  - Automatically triggers plan generation when needed
  - Provides both conversational response + plan

**Key Features:**
```typescript
- Graceful error recovery from malformed tool calls
- Automatic placeholder-based plan generation
- Logging at each decision point for debugging
- Non-blocking fallback mechanism
```

#### 2. `src/services/conversation/prompts/dedicatedPlannerPrompt.ts`
**Changes:**
- Added "HANDLING VAGUE REQUESTS - USE PLACEHOLDERS" section
- Clarified that placeholders should ALWAYS be used for missing params
- Specified `{{PLACEHOLDER_*}}` format consistently
- Changed guidance: always use "ready" status when using placeholders
- Provided concrete examples of placeholder usage
- Removed emphasis on "conditional" status

**Benefits:**
```
- LLM receives clearer instructions
- Less ambiguity about parameter handling
- Simpler for LLM to generate valid plans
- Better UI integration
```

## Flow Diagram: Request â†’ Response

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: "please make an example meeting in my calendar"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConversationService.processMessageAndAggregateResults()     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Tool Detectionâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ runConversationalStream()    â”‚
              â”‚ (Try LLM with tool choice)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Try JSON Parsing of Tool   â”‚
            â”‚ Call Arguments             â”‚
            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
                 â”‚ Success          â”‚ Malformed JSON
                 â†“                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Generate     â”‚    â”‚ Catch Error         â”‚
         â”‚ Conversational   â”‚ generatePlanWith    â”‚
         â”‚ Response     â”‚    â”‚ Placeholders()      â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â†“
                â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚            â”‚ LLM Creates Plan     â”‚
                â”‚            â”‚ with {{PLACEHOLDER}} â”‚
                â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â†“
                â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚            â”‚ Parse JSON Plan      â”‚
                â”‚            â”‚ Add to aggregatedTC  â”‚
                â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                     â†“
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Return ProcessedMessageResult:       â”‚
        â”‚ - conversationalResponse             â”‚
        â”‚ - aggregatedToolCalls (with plan)    â”‚
        â”‚ - toolCalls: true (if plan generated)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Stream to WebSocket Client:          â”‚
        â”‚ - conversational_text_segment        â”‚
        â”‚ - run_updated (with action steps)    â”‚
        â”‚ - UI detects placeholders in args    â”‚
        â”‚ - Shows form for parameter input     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## UI Integration Points

### What the Frontend Should Expect

#### 1. **Conversational Response**
```json
{
  "type": "conversational_text_segment",
  "content": "I'd be happy to create a meeting for you. Let me set that up!",
  "messageId": "234f5d8b-c195-49d9-a840-82d17bdb24da",
  "streamType": "conversational"
}
```

#### 2. **Run with Action Steps (containing placeholders)**
```json
{
  "type": "run_updated",
  "content": {
    "toolExecutionPlan": [
      {
        "stepId": "action_1",
        "toolCall": {
          "id": "action_1",
          "name": "create_calendar_event",
          "arguments": {
            "title": "{{PLACEHOLDER_meeting_title}}",
            "startTime": "{{PLACEHOLDER_start_time}}",
            "duration": "{{PLACEHOLDER_duration_minutes}}",
            "attendees": ["{{PLACEHOLDER_attendee_email}}"]
          }
        },
        "status": "ready"
      }
    ]
  }
}
```

#### 3. **UI Rendering Logic**
```javascript
// Detect placeholders in arguments
function extractPlaceholders(arguments) {
  const placeholders = [];
  const regex = /\{\{PLACEHOLDER_(\w+)\}\}/g;
  let match;
  while ((match = regex.exec(JSON.stringify(arguments))) !== null) {
    placeholders.push({
      field: match[1],
      placeholder: match[0]
    });
  }
  return placeholders;
}

// Show form for missing parameters
if (placeholders.length > 0) {
  showParameterForm(placeholders);
} else {
  enableExecuteButton();
}
```

## Improvements & Best Practices

### 1. **Error Resilience**
- âœ… Malformed JSON from LLM doesn't crash the system
- âœ… Graceful fallback to alternative approach
- âœ… Comprehensive logging at each decision point

### 2. **Simpler LLM Prompting**
- âœ… Placeholder format is unambiguous
- âœ… LLM doesn't need to understand complex conditional logic
- âœ… Lower cognitive load on the model
- âœ… More reliable output

### 3. **Better UX**
- âœ… User always gets immediate conversational response
- âœ… Plan is generated automatically when vague
- âœ… UI can show forms for missing parameters
- âœ… No waiting for clarification questions

### 4. **Maintainability**
- âœ… Clear separation of concerns
- âœ… Explicit placeholder format (`{{PLACEHOLDER_*}}`)
- âœ… Reduced code complexity
- âœ… Easier to debug and extend

## Testing Recommendations

### 1. **Calendar Tool Integration Test**
```
Scenario: "Create a meeting with the sales team tomorrow at 2pm"
Expected:
- âœ… Conversational response received
- âœ… Create_calendar_event tool identified
- âœ… Run object returned with action steps
- âœ… All parameters filled (no placeholders)
- âœ… Can proceed directly to execution
```

### 2. **Vague Request Test (Placeholder Fallback)**
```
Scenario: "make a meeting on my calendar"
Expected:
- âœ… Conversational response received
- âœ… Plan generated with placeholders:
  - {{PLACEHOLDER_title}}
  - {{PLACEHOLDER_startTime}}
  - {{PLACEHOLDER_duration}}
  - {{PLACEHOLDER_attendees}}
- âœ… UI shows form for parameters
- âœ… User can fill in and execute
```

### 3. **Malformed JSON Recovery Test**
```
Scenario: LLM returns malformed tool call arguments
Expected:
- âœ… Error caught gracefully
- âœ… Fallback to plan generation
- âœ… Plan with placeholders returned
- âœ… System continues without crash
```

### 4. **Concurrent Response Streaming Test**
```
Scenario: Both conversational response and plan generation
Expected:
- âœ… Conversational text streams immediately
- âœ… Plan updates/run_updated streamed in parallel
- âœ… Both arrive at client
- âœ… UI shows both response and action steps
```

## Monitoring & Logging

### Key Log Patterns to Monitor

#### Success Path (with placeholders):
```
ðŸ”¥ No valid tool calls from conversational stream, attempting plan generation
ðŸ”¥ Generating plan with placeholders for vague request
ðŸ”¥ Successfully parsed plan with placeholders
ðŸ”¥ Plan generation response received
```

#### Error Recovery Path:
```
ðŸ”¥ Malformed tool call detected - will attempt plan generation with placeholders
ðŸ”¥ Error in LLM stream iteration: 400 Failed to parse tool call arguments
ðŸ”¥ No valid tool calls from conversational stream
```

#### Normal Path (with complete parameters):
```
ðŸ”¥ Conversational stream: LLM response complete
toolCallCount: 1
toolCallNames: ["create_calendar_event"]
```

## Future Enhancements

1. **Parameter Persistence**
   - Remember previously entered parameters for similar requests
   - Auto-fill placeholders based on context

2. **Smart Placeholder Detection**
   - Automatically extract possible values from conversation history
   - Pre-fill placeholders when high confidence values exist

3. **Progressive Refinement**
   - Allow user to refine parameters in subsequent messages
   - Update plan with clarified values

4. **Validation at Execution**
   - Validate filled-in placeholder values against tool schema
   - Show errors if invalid and request correction

5. **Template System**
   - Create templates for common requests
   - Suggest templates to user based on request similarity

## Conclusion

The new implementation provides a more reliable, user-friendly approach to handling vague requests and tool call failures. By using placeholders and enabling parallel response streaming, the system achieves:

- **Robustness**: No crashes on malformed LLM output
- **Simplicity**: Clearer prompts lead to more reliable LLM behavior
- **UX**: Immediate feedback with gradual parameter collection
- **Maintainability**: Simpler code, easier to debug and extend

The placeholder-based approach is significantly more reliable than relying on complex conditional status flags, and it better matches real-world usage patterns where users often provide vague initial requests.

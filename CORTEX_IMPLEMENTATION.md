# Cortex Event Automation System - Integration Complete âœ…

## Overview
The complete Cortex event automation pipeline has been successfully integrated into your backend. This system enables natural language-based event automation across Gmail, Google Calendar, and Salesforce.

---

## Files Created

### Core Modules (8 files in `src/cortex/`)

| File | Purpose | Status |
|------|---------|--------|
| `types.ts` | Type definitions for Events, Units, Runs, Conditions, Actions | âœ… Created |
| `store.ts` | Hybrid Redis + Postgres storage layer | âœ… Created |
| `poller.ts` | Polls providers via Nango, emits events | âœ… Created |
| `compiler.ts` | Compiles natural language to structured Units using Groq LLM | âœ… Created |
| `matcher.ts` | Matches events to Units, creates Runs | âœ… Created |
| `runtime.ts` | Executes Runs and actions | âœ… Created |
| `routes.ts` | REST API endpoints (`/api/cortex`) | âœ… Created |
| `tools.ts` | Tool executor bridge to ToolOrchestrator | âœ… Created |

### Database Migration

| File | Purpose | Status |
|------|---------|--------|
| `migrations/001_cortex.sql` | Postgres schema (connections, units, runs, run_steps) | âœ… Created |

### Integration

| Change | Location | Status |
|--------|----------|--------|
| Cortex initialization | `src/index.ts` (lines ~100-150) | âœ… Added |
| Route registration | `src/index.ts` (lines ~150-160) | âœ… Added |
| Connection endpoint | `src/index.ts` (lines ~160-190) | âœ… Added |
| Graceful shutdown | `src/index.ts` (end of file) | âœ… Added |

---

## Key Components

### 1. Type System (`types.ts`)
- **Event**: External events from providers (gmail, google-calendar, salesforce)
- **Unit**: Automation rule (WHEN â†’ IF â†’ THEN)
- **Run**: Execution instance of a Unit for an Event
- **Trigger**: Event-based or schedule-based
- **Condition**: eval, semantic, or absence conditions
- **Action**: tool, llm, or wait actions

### 2. Storage (`store.ts`)
- **Redis**: Events (ephemeral), dedupe tracking, sync state, waiting runs
- **Postgres**: Units (permanent), Runs (history), Run Steps (audit trail)
- Hybrid approach balances speed + persistence

### 3. Compiler (`compiler.ts`)
- Converts natural language to JSON Units using Groq LLM
- Example: "When a deal closes, ping me" â†’ structured Unit
- Validates required fields (trigger, actions)

### 4. Matcher (`matcher.ts`)
- Finds Units matching incoming Events
- Evaluates trigger filters and conditions
- Creates Runs when matches found
- Supports semantic classification (urgency, sentiment, etc.)

### 5. Runtime (`runtime.ts`)
- Executes Runs step-by-step
- Handles three action types: tool, llm, wait
- Manages context and template resolution
- Supports async/await actions (wait, then resume)

### 6. Poller (`poller.ts`)
- Continuously polls connected providers via Nango
- Transforms provider data into Cortex Events
- Deduplication via Redis
- Error handling with exponential backoff

### 7. Routes (`routes.ts`)
- REST API for Units (CRUD)
- REST API for Runs (list, view, rerun)
- Provider-agnostic interface

### 8. Tool Executor (`tools.ts`)
- Bridges Cortex to existing ToolOrchestrator
- Maps Cortex tool names to ToolOrchestrator methods
- Example: `slack.send` â†’ ToolOrchestrator.executeTool

---

## Database Schema

```sql
connections
â”œâ”€â”€ id, user_id, provider, connection_id
â”œâ”€â”€ enabled, last_poll_at, error_count, last_error
â””â”€â”€ Unique(user_id, provider)

units
â”œâ”€â”€ id, owner_id, name
â”œâ”€â”€ raw_when, raw_if, raw_then (original user input)
â”œâ”€â”€ compiled_when, compiled_if, compiled_then (JSON)
â”œâ”€â”€ status (active, paused, disabled)
â”œâ”€â”€ trigger_source, trigger_event (for fast lookup)
â””â”€â”€ created_at, updated_at, run_count, last_run_at, last_run_status

runs
â”œâ”€â”€ id, unit_id, event_id, user_id
â”œâ”€â”€ status, current_step, context
â”œâ”€â”€ started_at, completed_at, resume_at, error
â””â”€â”€ original_event_payload (for reruns)

run_steps
â”œâ”€â”€ run_id, step_index
â”œâ”€â”€ action_type, action_config
â”œâ”€â”€ status, result, error
â””â”€â”€ started_at, completed_at
```

---

## API Endpoints

### Units
```
GET    /api/cortex/units              â†’ List user's units
GET    /api/cortex/units/:id          â†’ Get unit details
POST   /api/cortex/units              â†’ Create unit from natural language
PATCH  /api/cortex/units/:id/status   â†’ Update status (active/paused/disabled)
DELETE /api/cortex/units/:id          â†’ Delete unit
GET    /api/cortex/units/:id/runs     â†’ Get unit's run history
```

### Runs
```
GET    /api/cortex/runs               â†’ List user's runs
GET    /api/cortex/runs/:id           â†’ Get run details + steps
POST   /api/cortex/runs/:id/rerun     â†’ Rerun a previous execution
```

### Connections
```
POST   /api/connections               â†’ Register provider connection
```

---

## Usage Flow

### 1. Register a Connection
```bash
curl -X POST http://localhost:8080/api/connections \
  -H "x-user-id: user_123" \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "google-mail",
    "connectionId": "nango_connection_id"
  }'
```

### 2. Create an Automation (Unit)
```bash
curl -X POST http://localhost:8080/api/cortex/units \
  -H "x-user-id: user_123" \
  -H "Content-Type: application/json" \
  -d '{
    "when": "when I receive an email",
    "if": "it sounds urgent",
    "then": "summarize it and send me a Slack message"
  }'
```

Response:
```json
{
  "unit": {
    "id": "unit_abc123",
    "name": "I receive an email",
    "when": {
      "type": "event",
      "source": "gmail",
      "event": "email_received"
    },
    "if": [
      {
        "type": "semantic",
        "prompt": "detect_urgency",
        "input": "{{payload.body_text}}",
        "expect": "urgent"
      }
    ],
    "then": [
      {
        "type": "llm",
        "prompt": "summarize",
        "input": { "text": "{{payload.body_text}}" },
        "store_as": "summary"
      },
      {
        "type": "tool",
        "tool": "slack.send",
        "args": { "channel": "#alerts", "text": "ðŸš¨ {{summary}}" }
      }
    ],
    "status": "active",
    "created_at": "2025-12-07T...",
    "updated_at": "2025-12-07T..."
  }
}
```

### 3. Event Triggers Automation
```
[Poller] â†’ Detects new email
   â†“
[Event] â†’ email_received event created
   â†“
[Matcher] â†’ Finds matching Units
   â†“
[Run] â†’ Created and queued
   â†“
[Runtime] â†’ Executes actions in order
   â†“
[Result] â†’ Slack message sent
```

### 4. Check Run History
```bash
curl http://localhost:8080/api/cortex/runs \
  -H "x-user-id: user_123"
```

---

## Execution Flow Example

**Natural Language:**
```
When a deal closes over $10k, post to #wins channel
```

**Compiled Unit:**
```json
{
  "when": {
    "type": "event",
    "source": "salesforce",
    "event": "opportunity_closed_won",
    "filter": "payload.amount > 10000"
  },
  "if": [],
  "then": [
    {
      "type": "tool",
      "tool": "slack.send",
      "args": {
        "channel": "#wins",
        "text": "ðŸŽ‰ {{payload.name}} closed for ${{payload.amount}}!"
      }
    }
  ]
}
```

**Execution:**
1. Poller detects: `opportunity_closed_won` event from Salesforce
2. Matcher evaluates: `payload.amount > 10000` âœ“ (true)
3. Creates Run with payload stored in context
4. Runtime executes: `slack.send` with resolved args
5. Result: Message posted to #wins

---

## Next Steps

### 1. Run Database Migration
```bash
# Apply schema
psql $DATABASE_URL < migrations/001_cortex.sql
```

### 2. Test the System
```bash
# Create a test unit
curl -X POST http://localhost:8080/api/cortex/units \
  -H "x-user-id: test_user" \
  -H "Content-Type: application/json" \
  -d '{
    "when": "when I receive an email",
    "then": "summarize it"
  }'
```

### 3. Monitor Runs
```bash
# List all runs for user
curl http://localhost:8080/api/cortex/runs \
  -H "x-user-id: test_user"

# Get specific run details
curl http://localhost:8080/api/cortex/runs/run_abc123 \
  -H "x-user-id: test_user"
```

---

## Configuration

The system uses existing configs:
- `CONFIG.GROQ_API_KEY` - Groq API for compilation & LLM actions
- `CONFIG.REDIS_URL` - Redis for ephemeral storage
- `DATABASE_URL` - Postgres for persistent storage
- Existing `NangoService` for provider polling

No additional environment variables needed!

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Cortex Event System                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Poller     â”‚  (polls every 60s)
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Gmail, Google Calendar, Salesforce
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    Event     â”‚  (writes to Redis with dedupe)
  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ /redis/event:{id}
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Matcher    â”‚  (queries Postgres)
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ SELECT units WHERE trigger_source = source
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Evaluate conditions
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚     Run      â”‚  (insert to Postgres)
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ /units/{id}/runs
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Runtime    â”‚  (execute actions)
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ LLM: generate text
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Tool: call ToolOrchestrator
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Wait: defer execution
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Result     â”‚  (logged to run_steps)
  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Slack, Email, Salesforce, etc.
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Status Summary

âœ… **All files created and integrated:**
- 8 core Cortex modules
- 1 database migration
- 4 integration points in index.ts
- Complete API documentation

âœ… **Ready to:**
- Run migrations
- Deploy to production
- Handle real events from providers

â“ **Questions?**
Refer to the specification or individual file comments for detailed logic.

---

## File Locations

```
/Users/lutendolukhele/Desktop/backedn-main/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cortex/
â”‚   â”‚   â”œâ”€â”€ types.ts         # Event, Unit, Run, Condition, Action
â”‚   â”‚   â”œâ”€â”€ store.ts         # Hybrid Redis + Postgres
â”‚   â”‚   â”œâ”€â”€ compiler.ts      # NL â†’ Unit (Groq)
â”‚   â”‚   â”œâ”€â”€ matcher.ts       # Event â†’ Units â†’ Runs
â”‚   â”‚   â”œâ”€â”€ runtime.ts       # Execute runs
â”‚   â”‚   â”œâ”€â”€ routes.ts        # REST API
â”‚   â”‚   â”œâ”€â”€ tools.ts         # ToolOrchestrator bridge
â”‚   â”‚   â””â”€â”€ poller.ts        # Poll providers
â”‚   â”‚
â”‚   â””â”€â”€ index.ts             # âœ… Updated with Cortex integration
â”‚
â””â”€â”€ migrations/
    â””â”€â”€ 001_cortex.sql       # Database schema
```

---

Generated: 2025-12-07
Status: **COMPLETE & READY FOR INTEGRATION**
